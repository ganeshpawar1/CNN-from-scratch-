{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"digit-recognizer\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    Z_stable = Z - np.max(Z, axis=0, keepdims=True)\n",
    "    Z_stable = np.clip(Z_stable,-1e10,1e10)\n",
    "    exp_Z = np.exp(Z_stable)  # Stabilize by subtracting max\n",
    "    return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def compute_loss(A3, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    m = Y.size\n",
    "    loss = -np.sum(one_hot_Y * np.log(A3)) / m\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D(images, filters):\n",
    "    # Get shapes of images and filters\n",
    "    batch_size, image_height, image_width, image_depth = images.shape\n",
    "    num_filters, filter_height, filter_width, filter_depth = filters.shape\n",
    "    \n",
    "    # Validate that the filter depth matches the image depth\n",
    "    if image_depth != filter_depth:\n",
    "        raise ValueError(\"The depth of the images and filters must match\")\n",
    "\n",
    "    # Calculate output dimensions\n",
    "    output_height = image_height - filter_height + 1\n",
    "    output_width = image_width - filter_width + 1\n",
    "\n",
    "    # Prepare an empty output array\n",
    "    output = np.zeros((batch_size, output_height, output_width, num_filters))\n",
    "\n",
    "    # Perform the convolution operation\n",
    "    for b in range(batch_size):  # Iterate over batch\n",
    "        for f in range(num_filters):  # Iterate over filters\n",
    "            for y in range(output_height):\n",
    "                for x in range(output_width):\n",
    "                    # Define the region of the image being processed\n",
    "                    region = images[b, y:y+filter_height, x:x+filter_width, :]\n",
    "                    \n",
    "                    # Perform the convolution: element-wise multiplication and sum\n",
    "                    output[b, y, x, f] = np.sum(region * filters[f, :, :, :])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxPool(images, pool_size, stride=2):\n",
    "    batch_size, image_height, image_width, image_depth = images.shape\n",
    "    pool_height, pool_width = pool_size\n",
    "\n",
    "    output_height = (image_height - pool_height) // stride + 1\n",
    "    output_width = (image_width - pool_width) // stride + 1\n",
    "\n",
    "    if output_height <= 0 or output_width <= 0:\n",
    "        raise ValueError(\"Pooling window or stride is too large for the given image dimensions.\")\n",
    "\n",
    "    output = np.zeros((batch_size, output_height, output_width, image_depth))\n",
    "\n",
    "    for b in range(batch_size):  # Iterate over batch\n",
    "        for d in range(image_depth):  # Iterate over depth\n",
    "            for y in range(output_height):\n",
    "                for x in range(output_width):\n",
    "                    start_y = y * stride\n",
    "                    start_x = x * stride\n",
    "                    end_y = start_y + pool_height\n",
    "                    end_x = start_x + pool_width\n",
    "\n",
    "                    pooling_window = images[b, start_y:end_y, start_x:end_x, d]\n",
    "                    output[b, y, x, d] = np.max(pooling_window)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(X, Y, batch_size=64):\n",
    "    num_samples = X.shape[0]\n",
    "    indices = np.random.permutation(num_samples)  # Shuffle indices\n",
    "    X = X[indices]\n",
    "    Y = Y[indices]\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        X_batch = X[i:i + batch_size]\n",
    "        Y_batch = Y[i:i + batch_size]\n",
    "        yield X_batch, Y_batch\n",
    "\n",
    "def init_params():\n",
    "    # Convolutional layers\n",
    "    W1 = np.random.rand(8, 3, 3, 1) - 0.5\n",
    "    b1 = np.random.rand(8,1) - 0.5\n",
    "\n",
    "    # Fully connected layers\n",
    "    W2 = np.random.rand(1352, 64) - 0.5\n",
    "    b2 = np.random.rand(64,1)-0.5\n",
    "    W3 = np.random.rand(64, 10)-0.5\n",
    "    b3 = np.random.rand(10,1)-0.5\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "\n",
    "\n",
    "def Flatten(X):\n",
    "    return X.reshape(-1)\n",
    "\n",
    "def ForwardProp(X, W1, b1, W2, b2, W3, b3):\n",
    "    # First Convolution Layer\n",
    "    Z1 = conv2D(X, W1) + b1.reshape(1, 1, 1, -1)\n",
    "    A1 = ReLU(Z1)\n",
    "    P1 = MaxPool(A1, pool_size=(2, 2))\n",
    "\n",
    "    # Flattening the pooled output\n",
    "    F = P1.reshape(P1.shape[0], -1)  # Flatten the output to match W3 dimensions\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    Z2 = np.dot(F, W2) + b2 \n",
    "    A2 = ReLU(Z2)\n",
    "\n",
    "    Z3 = A2.dot(W3) + b3.T\n",
    "    A3 = softmax(Z3)\n",
    "\n",
    "    return Z1, A1, P1, Z2, A2, F, Z3, A3\n",
    "\n",
    "def MaxPool_backward_multi_channel(A_prev, grad_out, pool_size=(2, 2), stride=2):\n",
    "    print(\"A_prev.shape:\", A_prev.shape)\n",
    "    print(\"grad_out.shape:\", grad_out.shape)\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (m, n_H, n_W, n_C) = grad_out.shape\n",
    "    grad_input = np.zeros_like(A_prev)\n",
    "    \n",
    "    pool_height, pool_width = pool_size\n",
    "    \n",
    "    for b in range(m):  # Iterate over the batch dimension\n",
    "        for h in range(n_H):  # Iterate over height dimension\n",
    "            for w in range(n_W):  # Iterate over width dimension\n",
    "                for c in range(n_C):  # Iterate over channels\n",
    "                    # Define the window for max pooling\n",
    "                    start_i = h * stride\n",
    "                    start_j = w * stride\n",
    "                    end_i = start_i + pool_height\n",
    "                    end_j = start_j + pool_width\n",
    "                    \n",
    "                    # Ensure indices are within bounds\n",
    "                    if end_i <= n_H_prev and end_j <= n_W_prev:\n",
    "                        window = A_prev[b, start_i:end_i, start_j:end_j, c]\n",
    "                        # Find the index of the maximum value in the window\n",
    "                        #print(\"Window:\", window)\n",
    "                        max_idx = np.unravel_index(np.argmax(window), window.shape)\n",
    "                        grad_input[b, start_i + max_idx[0], start_j + max_idx[1], c] = grad_out[b, h, w, c]\n",
    "                    else:\n",
    "                        # Handle edge cases where the pooling window might be out of bounds\n",
    "                        grad_input[b, start_i:end_i, start_j:end_j, c] += grad_out[b, h, w, c]\n",
    "    \n",
    "    return grad_input\n",
    "\n",
    "def backward_conv2D(dZ, X, W):\n",
    "    \"\"\"\n",
    "    Perform backward convolution.\n",
    "    Args:\n",
    "        dZ: Gradients from the next layer, shape (batch_size, output_height, output_width, n_filters).\n",
    "        X: Input to the forward pass, shape (batch_size, input_height, input_width, input_channels).\n",
    "        W: Filters used in the forward pass, shape (n_filters, filter_height, filter_width, input_channels).\n",
    "    Returns:\n",
    "        dX: Gradient w.r.t input, shape same as X.\n",
    "        dW: Gradient w.r.t weights, shape same as W.\n",
    "        db: Gradient w.r.t biases, shape (n_filters, 1).\n",
    "    \"\"\"\n",
    "    batch_size, output_height, output_width, n_filters = dZ.shape\n",
    "    _, input_height, input_width, input_channels = X.shape\n",
    "    n_filters, filter_height, filter_width, input_channels = W.shape\n",
    "\n",
    "    # Initialize gradients\n",
    "    dX = np.zeros_like(X)\n",
    "    dW = np.zeros_like(W)\n",
    "    db = np.zeros((n_filters, 1))  # Ensure db has shape (n_filters, 1)\n",
    "\n",
    "    # Perform backward convolution\n",
    "    for i in range(batch_size):\n",
    "        for f in range(n_filters):\n",
    "            for h in range(output_height):\n",
    "                for w in range(output_width):\n",
    "                    # Slice the region of input X that contributed to dZ\n",
    "                    x_slice = X[i, h:h+filter_height, w:w+filter_width, :]\n",
    "                    # Accumulate gradients for W\n",
    "                    dW[f, :, :, :] += x_slice * dZ[i, h, w, f]\n",
    "                    # Accumulate gradients for X\n",
    "                    dX[i, h:h+filter_height, w:w+filter_width, :] += W[f, :, :, :] * dZ[i, h, w, f]\n",
    "                    # Accumulate gradients for biases\n",
    "                    db[f, 0] += dZ[i, h, w, f]  # Update db with shape (n_filters, 1)\n",
    "\n",
    "    return dX, dW, db\n",
    "\n",
    "\n",
    "def MaxPool_upsample(dA, A_prev, pool_size=(2, 2), stride=2):\n",
    "    \"\"\"\n",
    "    Upsample the gradient from MaxPooling to match the input dimensions.\n",
    "    \"\"\"\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (m, n_H, n_W, n_C) = dA.shape\n",
    "    upsampled = np.zeros_like(A_prev)\n",
    "    \n",
    "    pool_height, pool_width = pool_size\n",
    "    \n",
    "    for b in range(m):  # Iterate over the batch\n",
    "        for h in range(n_H):  # Iterate over the height\n",
    "            for w in range(n_W):  # Iterate over the width\n",
    "                for c in range(n_C):  # Iterate over the channels\n",
    "                    start_i = h * stride\n",
    "                    start_j = w * stride\n",
    "                    end_i = start_i + pool_height\n",
    "                    end_j = start_j + pool_width\n",
    "                    \n",
    "                    window = A_prev[b, start_i:end_i, start_j:end_j, c]\n",
    "                    max_idx = np.unravel_index(np.argmax(window), window.shape)\n",
    "                    \n",
    "                    upsampled[b, start_i + max_idx[0], start_j + max_idx[1], c] = dA[b, h, w, c]\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def BackwardProp(X, Y, Z1, A1, P1, Z2, A2, F, Z3, A3,W1, b1, W2, b2, W3, b3):\n",
    "    m = X.shape[0]# number of batches\n",
    "    dZ3 = A3 - one_hot(Y).T #(64,10)\n",
    "    dW3 = 1/m * np.dot(A2.T,dZ3)#(64,10)\n",
    "    db3 = 1/m * np.sum(dZ3,axis=0,keepdims=True).T#(10,1)\n",
    "\n",
    "    dA2 = np.dot(dZ3,W3.T)#(64,64)\n",
    "    dZ2 = np.dot(dA2,ReLU_deriv(Z2))#(64,64)\n",
    "    dW2 = 1/m * np.dot(F.T,dZ2)#(1352,64)\n",
    "    db2 = 1/m * np.sum(dZ2,axis=1,keepdims=True)#(64,1)\n",
    "\n",
    "    dF = np.dot(dZ2,W2.T)#(64,1352)\n",
    "\n",
    "    dP1 = dF.reshape(P1.shape)\n",
    "\n",
    "    dA1 = MaxPool_upsample(dP1,A1)\n",
    "    dZ1 = dA1 * ReLU_deriv(Z1)\n",
    "    dX,dW1,db1 = backward_conv2D(dZ1,X,W1)\n",
    "    dW1 = 1/m * dW1\n",
    "    db1 = 1/m * db1\n",
    "    return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "\n",
    "\n",
    "def UpdateParams(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, lr):\n",
    "    # Update weights and biases using gradient descent\n",
    "    #learning_rate:lr\n",
    "    W1 -= lr * dW1\n",
    "    b1 -= lr * db1\n",
    "    W2 -= lr * dW2\n",
    "    b2 -= lr * db2\n",
    "    W3 -= lr * dW3\n",
    "    b3 -= lr * db3\n",
    "    \n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "def Train(X,Y,epochs,batch_size,lr):\n",
    "    W1, b1, W2, b2, W3, b3 = init_params()\n",
    "    num_samples = X.shape[0]\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    for epoch in range(epochs+1):\n",
    "        for X_batch,Y_batch in generate_batches(X,Y,batch_size):\n",
    "            print(f\"Count:{count}\")\n",
    "            Z1, A1, P1, Z2, A2, F, Z3, A3 = ForwardProp(X_batch,W1, b1, W2, b2, W3, b3)\n",
    "            \n",
    "            batch_loss = -np.mean(np.sum(one_hot(Y_batch).T * np.log(A3 + 1e-8), axis=1))\n",
    "            total_loss += batch_loss\n",
    "            \n",
    "            dW1, db1, dW2, db2, dW3, db3 = BackwardProp(X_batch,Y_batch,Z1, A1, P1, Z2, A2, F, Z3, A3,W1, b1, W2, b2, W3, b3)\n",
    "            W1, b1, W2, b2, W3, b3 = UpdateParams( W1, b1, W2, b2, W3, b3,dW1, db1, dW2, db2, dW3, db3,lr)\n",
    "            count += 1\n",
    "        avg_loss = total_loss / (num_samples // batch_size)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
    "\n",
    "data_dev = data[0:1000]\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "data_train = data[41936:m]\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data_train[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(-1, 28, 28, 1)  # Reshape to (num_samples, 28, 28, 1)\n",
    "images = images/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:0\n",
      "Epoch 1/1, Loss: 5.7593\n",
      "Count:1\n",
      "Epoch 2/1, Loss: 11.0329\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3 = Train(X=images,Y=label,epochs=1,batch_size=64,lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
